{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92eff1e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T05:41:33.865822Z",
     "iopub.status.busy": "2024-08-28T05:41:33.865474Z",
     "iopub.status.idle": "2024-08-28T05:41:56.338866Z",
     "shell.execute_reply": "2024-08-28T05:41:56.337980Z"
    },
    "id": "2jyOTfb_poJs",
    "outputId": "be9bc22c-1fdf-4b91-9e8f-6f3f588a2b34",
    "papermill": {
     "duration": 22.480287,
     "end_time": "2024-08-28T05:41:56.341480",
     "exception": false,
     "start_time": "2024-08-28T05:41:33.861193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:13<00:00, 13069976.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define the transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "\n",
    "def train_test_split_custom(X, y=None, test_size=0.1, random_state=None, stratify=None):\n",
    "    if random_state is not None:\n",
    "        torch.manual_seed(random_state)\n",
    "    if isinstance(test_size, float):\n",
    "        test_size = int(test_size * len(X))\n",
    "    indices = torch.randperm(len(X))\n",
    "    if stratify is not None:\n",
    "        stratify_indices = torch.argsort(torch.Tensor(stratify))\n",
    "        indices = indices[stratify_indices]\n",
    "\n",
    "    test_indices = indices[:test_size]\n",
    "    train_indices = indices[test_size:]\n",
    "\n",
    "    X_train, X_test = X[train_indices], X[test_indices]\n",
    "    if not y:\n",
    "        return X_train, X_test\n",
    "    else :\n",
    "        y_train, y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Image Downloader\n",
    "image_dataset_downloader = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform)\n",
    "\n",
    "image_dataset_downloader_test = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform)\n",
    "\n",
    "train_idx, validation_idx = train_test_split_custom(torch.arange(len(image_dataset_downloader)),\n",
    "                                             test_size=0.1,\n",
    "                                             random_state=999,\n",
    "                                             stratify=image_dataset_downloader.targets)\n",
    "\n",
    "image_train_data = torch.utils.data.Subset(image_dataset_downloader,train_idx)\n",
    "image_val_data = torch.utils.data.Subset(image_dataset_downloader,validation_idx)\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, split):\n",
    "        super().__init__()\n",
    "        self.datasplit = split\n",
    "\n",
    "        if self.datasplit == \"train\":\n",
    "            self.dataset = image_train_data\n",
    "        elif self.datasplit == \"val\":\n",
    "            self.dataset = image_val_data\n",
    "        elif self.datasplit == \"test\":\n",
    "            self.dataset = image_dataset_downloader_test\n",
    "        else:\n",
    "            raise ValueError(\"Invalid split argument. Choose from 'train', 'val', or 'test'.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.dataset[index]\n",
    "        return img, target\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += shortcut\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class Resnet_Q1(nn.Module):\n",
    "    def __init__(self,): # DO NOT CHANGE __init__ arguements\n",
    "        super(Resnet_Q1, self).__init__()\n",
    "        self.initial_conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.initial_bn1 = nn.BatchNorm2d(64)\n",
    "        self.initial_relu1 = nn.ReLU(inplace=True)\n",
    "        self.initial_conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.initial_bn2 = nn.BatchNorm2d(64)\n",
    "        self.initial_relu2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        # Define rest 17 Residual Blocks\n",
    "        self.layer1 = self._make_layer(17, 64, 64)\n",
    "\n",
    "        # Final  full connected layer\n",
    "        self.fc = nn.Linear(65536, 10)\n",
    "\n",
    "    def _make_layer(self, num_blocks, in_channels, out_channels):\n",
    "        layers = []\n",
    "        for _ in range(num_blocks):\n",
    "            layers.append(ResidualBlock(in_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial_conv1(x)\n",
    "        x = self.initial_bn1(x)\n",
    "        x = self.initial_relu1(x)\n",
    "        x = self.initial_conv2(x)\n",
    "        x = self.initial_bn2(x)\n",
    "        x = self.initial_relu2(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class VGG_Q2(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(VGG_Q2, self).__init__()\n",
    "        self.init_channels = 64\n",
    "        self.num_classes = 10\n",
    "        self.features = self._make_layers()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(13, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, self.num_classes),\n",
    "        )\n",
    "\n",
    "\n",
    "    def _make_layers(self):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        current_channels = self.init_channels\n",
    "        kernel_size = 3\n",
    "\n",
    "        cfg = [2, 2, 3, 3, 3]\n",
    "\n",
    "        for num_convs in cfg:\n",
    "            for _ in range(num_convs):\n",
    "                layers.append(nn.Conv2d(in_channels, current_channels, kernel_size=kernel_size, padding=kernel_size//2))\n",
    "                layers.append(nn.BatchNorm2d(current_channels))\n",
    "                layers.append(nn.ReLU(inplace=True))\n",
    "                in_channels = current_channels\n",
    "\n",
    "\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "            # Reduce channels by 35%\n",
    "            current_channels = math.ceil(current_channels * 0.65)\n",
    "\n",
    "            # Increase kernel size by 25% with ceil rounding\n",
    "            kernel_size = math.ceil(kernel_size * 1.25)\n",
    "\n",
    "            if kernel_size % 2 == 0:  # Ensure kernel size is odd for padding consistency\n",
    "                kernel_size += 1\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class CNABlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(CNABlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class InceptionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, final_out_channels): # DO NOT CHANGE __init__ arguements\n",
    "        super().__init__()\n",
    "\n",
    "        self.branch1x1 = CNABlock(in_channels, 64, kernel_size=1)\n",
    "\n",
    "        self.branch5x5_1 = CNABlock(in_channels, 48, kernel_size=3, padding=1)\n",
    "        self.branch5x5_2 = CNABlock(48, 64, kernel_size=5, padding=2)\n",
    "\n",
    "        self.branch5x5dbl_1 = CNABlock(in_channels, 48, kernel_size=3, padding=1)\n",
    "        self.branch5x5dbl_2 = CNABlock(48, 64, kernel_size=5, padding=2)\n",
    "\n",
    "        self.branch_pool = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            CNABlock(in_channels, 32, kernel_size=1)\n",
    "        )\n",
    "\n",
    "        # Compute the number of output channels after concatenation\n",
    "        concat_out_channels = 64 + 64 + 64 + 32\n",
    "        self.filter = CNABlock(concat_out_channels, final_out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch5x5 = self.branch5x5_1(x)\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "\n",
    "        branch5x5dbl = self.branch5x5dbl_1(x)\n",
    "        branch5x5dbl = self.branch5x5dbl_2(branch5x5dbl)\n",
    "\n",
    "        branch_pool = self.branch_pool(x)\n",
    "\n",
    "        outputs = [branch1x1, branch5x5, branch5x5dbl, branch_pool]\n",
    "        x = torch.cat(outputs, 1)\n",
    "        x = self.filter(x)\n",
    "        return x\n",
    "\n",
    "class Inception_Q3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Inception_Q3, self).__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            CNABlock(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.inception1 = InceptionBlock(in_channels=64, final_out_channels=128)\n",
    "        self.inception2 = InceptionBlock(in_channels=128, final_out_channels=256)\n",
    "        self.inception3 = InceptionBlock(in_channels=256, final_out_channels=512)\n",
    "        self.inception4 = InceptionBlock(in_channels=512, final_out_channels=1024)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(1024, 10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.stem(x)\n",
    "        x = self.inception1(x)\n",
    "        x = self.inception2(x)\n",
    "        x = self.inception3(x)\n",
    "        x = self.inception4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class CustomNetwork_Q4(nn.Module):\n",
    "    def __init__(self,) :\n",
    "        super(CustomNetwork_Q4, self).__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            CNABlock(in_channels=3, out_channels=128, kernel_size=7, stride=2, padding=3),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.residual1 = ResidualBlock(in_channels=128, out_channels=128)\n",
    "        self.residual2 = ResidualBlock(in_channels=128, out_channels=128)\n",
    "        self.inception1 = InceptionBlock(in_channels=128, final_out_channels=256)\n",
    "        self.inception2 = InceptionBlock(in_channels=256, final_out_channels=512)\n",
    "        self.residual3 = ResidualBlock(in_channels=512, out_channels=512)\n",
    "        self.inception3 = InceptionBlock(in_channels=512, final_out_channels=1024)\n",
    "        self.residual4 = ResidualBlock(in_channels=1024, out_channels=1024)\n",
    "        self.inception4 = InceptionBlock(in_channels=1024, final_out_channels=2048)\n",
    "        self.residual5 = ResidualBlock(in_channels=2048, out_channels=2048)\n",
    "        self.inception5 = InceptionBlock(in_channels=2048, final_out_channels=2048)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(2048, 10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.stem(x)\n",
    "        x = self.residual1(x)\n",
    "        x = self.residual2(x)\n",
    "        x = self.inception1(x)\n",
    "        x = self.inception2(x)\n",
    "        x = self.residual3(x)\n",
    "        x = self.inception3(x)\n",
    "        x = self.residual4(x)\n",
    "        x = self.inception4(x)\n",
    "        x = self.residual5(x)\n",
    "        x = self.inception5(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "def trainer(gpu=\"F\",\n",
    "            dataloader=None,\n",
    "            network=None,\n",
    "            criterion=None,\n",
    "            optimizer=None,\n",
    "            epoch=None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and gpu == \"T\" else \"cpu\")\n",
    "    network.to(device)\n",
    "    #print(list(network.parameters()))\n",
    "\n",
    "    network.train()\n",
    "    #running_loss = 0.0\n",
    "    prev_loss = 10000\n",
    "    count = 0\n",
    "\n",
    "    for i in range(0,epoch):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #print(list(network.parameters()))\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / len(dataloader)\n",
    "        if prev_loss - avg_loss < 0.0000000001:\n",
    "            count += 1\n",
    "        else:\n",
    "            count = 0\n",
    "        if count > 50:\n",
    "            break\n",
    "        prev_loss = avg_loss\n",
    "        if i%5 == 0:\n",
    "            print(f\"Training Loss: {avg_loss:.4f} at epoch: {i+1}\")\n",
    "\n",
    "\n",
    "def validator(gpu=\"F\",\n",
    "              dataloader=None,\n",
    "              network=None,\n",
    "              criterion=None,\n",
    "              optimizer=None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and gpu == \"T\" else \"cpu\")\n",
    "    network.to(device)\n",
    "\n",
    "    network.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "def test(gpu=\"F\",\n",
    "              dataloader=None,\n",
    "              network=None,\n",
    "              criterion=None,\n",
    "              optimizer=None):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and gpu == \"T\" else \"cpu\")\n",
    "    network.to(device)\n",
    "\n",
    "    network.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = network(inputs)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a48421b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T05:41:56.359637Z",
     "iopub.status.busy": "2024-08-28T05:41:56.358947Z",
     "iopub.status.idle": "2024-08-28T11:22:22.169352Z",
     "shell.execute_reply": "2024-08-28T11:22:22.167939Z"
    },
    "id": "LliRF6_UqXkr",
    "outputId": "797e0dcf-e847-46c3-fc3b-640248736e62",
    "papermill": {
     "duration": 20425.821558,
     "end_time": "2024-08-28T11:22:22.171501",
     "exception": false,
     "start_time": "2024-08-28T05:41:56.349943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Resnet_Q1 Architecture on train split of ImageDataset\n",
      "Training Loss: 2.6775 at epoch: 1\n",
      "Training Loss: 0.5471 at epoch: 6\n",
      "Training Loss: 0.1258 at epoch: 11\n",
      "Training Loss: 0.0966 at epoch: 16\n",
      "Training Loss: 0.0746 at epoch: 21\n",
      "Training Loss: 0.0795 at epoch: 26\n",
      "Training Loss: 0.0352 at epoch: 31\n",
      "Training Loss: 0.0538 at epoch: 36\n",
      "Training Loss: 0.0322 at epoch: 41\n",
      "Training Loss: 0.0405 at epoch: 46\n",
      "Training Loss: 0.0241 at epoch: 51\n",
      "Training Loss: 0.0280 at epoch: 56\n",
      "Training Loss: 0.0261 at epoch: 61\n",
      "Training Loss: 0.0165 at epoch: 66\n",
      "Training Loss: 0.0092 at epoch: 71\n",
      "Training Loss: 0.0215 at epoch: 76\n",
      "Training Loss: 0.0100 at epoch: 81\n",
      "Training Loss: 0.0102 at epoch: 86\n",
      "Training Loss: 0.0095 at epoch: 91\n",
      "Training Loss: 0.0136 at epoch: 96\n",
      "Validating Resnet_Q1 Architecture on val split of ImageDataset\n",
      "Validation Loss: 2.5647, Accuracy: 68.51%\n",
      "Testing Resnet_Q1 Architecture on test split of ImageDataset\n",
      "Test Accuracy: 67.92%\n",
      "Training VGG_Q2 Architecture on train split of ImageDataset\n",
      "Training Loss: 1.5308 at epoch: 1\n",
      "Training Loss: 0.6385 at epoch: 6\n",
      "Training Loss: 0.3574 at epoch: 11\n",
      "Training Loss: 0.2126 at epoch: 16\n",
      "Training Loss: 0.1325 at epoch: 21\n",
      "Training Loss: 0.0986 at epoch: 26\n",
      "Training Loss: 0.0835 at epoch: 31\n",
      "Training Loss: 0.0692 at epoch: 36\n",
      "Training Loss: 0.0584 at epoch: 41\n",
      "Training Loss: 0.0583 at epoch: 46\n",
      "Training Loss: 0.0497 at epoch: 51\n",
      "Training Loss: 0.0495 at epoch: 56\n",
      "Training Loss: 0.0461 at epoch: 61\n",
      "Training Loss: 0.0464 at epoch: 66\n",
      "Training Loss: 0.0382 at epoch: 71\n",
      "Training Loss: 0.0367 at epoch: 76\n",
      "Training Loss: 0.0327 at epoch: 81\n",
      "Training Loss: 0.0345 at epoch: 86\n",
      "Training Loss: 0.0313 at epoch: 91\n",
      "Training Loss: 0.0259 at epoch: 96\n",
      "Validating VGG_Q2 Architecture on val split of ImageDataset\n",
      "Validation Loss: 1.5516, Accuracy: 75.24%\n",
      "Testing VGG_Q2 Architecture on test split of ImageDataset\n",
      "Test Accuracy: 75.46%\n",
      "Training Inception_Q3 Architecture on train split of ImageDataset\n",
      "Training Loss: 1.3734 at epoch: 1\n",
      "Training Loss: 0.3901 at epoch: 6\n",
      "Training Loss: 0.1081 at epoch: 11\n",
      "Training Loss: 0.0624 at epoch: 16\n",
      "Training Loss: 0.0549 at epoch: 21\n",
      "Training Loss: 0.0413 at epoch: 26\n",
      "Training Loss: 0.0539 at epoch: 31\n",
      "Training Loss: 0.0351 at epoch: 36\n",
      "Training Loss: 0.0303 at epoch: 41\n",
      "Training Loss: 0.0327 at epoch: 46\n",
      "Training Loss: 0.0288 at epoch: 51\n",
      "Training Loss: 0.0320 at epoch: 56\n",
      "Training Loss: 0.0275 at epoch: 61\n",
      "Training Loss: 0.0207 at epoch: 66\n",
      "Training Loss: 0.0184 at epoch: 71\n",
      "Training Loss: 0.0213 at epoch: 76\n",
      "Training Loss: 0.0141 at epoch: 81\n",
      "Training Loss: 0.0225 at epoch: 86\n",
      "Training Loss: 0.0154 at epoch: 91\n",
      "Training Loss: 0.0182 at epoch: 96\n",
      "Validating Inception_Q3 Architecture on val split of ImageDataset\n",
      "Validation Loss: 1.7699, Accuracy: 72.40%\n",
      "Testing Inception_Q3 Architecture on test split of ImageDataset\n",
      "Test Accuracy: 71.80%\n",
      "Training CustomNetwork_Q4 Architecture on train split of ImageDataset\n",
      "Training Loss: 1.4045 at epoch: 1\n",
      "Training Loss: 0.4646 at epoch: 6\n",
      "Training Loss: 0.1656 at epoch: 11\n",
      "Training Loss: 0.0979 at epoch: 16\n",
      "Training Loss: 0.0742 at epoch: 21\n",
      "Training Loss: 0.0502 at epoch: 26\n",
      "Training Loss: 0.0508 at epoch: 31\n",
      "Training Loss: 0.0454 at epoch: 36\n",
      "Training Loss: 0.0313 at epoch: 41\n",
      "Training Loss: 0.0374 at epoch: 46\n",
      "Training Loss: 0.0312 at epoch: 51\n",
      "Training Loss: 0.0191 at epoch: 56\n",
      "Training Loss: 0.0252 at epoch: 61\n",
      "Training Loss: 0.0221 at epoch: 66\n",
      "Training Loss: 0.0242 at epoch: 71\n",
      "Training Loss: 0.0166 at epoch: 76\n",
      "Training Loss: 0.0238 at epoch: 81\n",
      "Training Loss: 0.0251 at epoch: 86\n",
      "Training Loss: 0.0165 at epoch: 91\n",
      "Training Loss: 0.0165 at epoch: 96\n",
      "Validating CustomNetwork_Q4 Architecture on val split of ImageDataset\n",
      "Validation Loss: 1.3999, Accuracy: 77.78%\n",
      "Testing CustomNetwork_Q4 Architecture on test split of ImageDataset\n",
      "Test Accuracy: 76.67%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.0001\n",
    "EPOCH = 100\n",
    "GPU ='T'\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    imageDataset = [\n",
    "        ImageDataset(split=\"train\"),\n",
    "        ImageDataset(split=\"val\"),\n",
    "        ImageDataset(split=\"test\")\n",
    "\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "    Architectures = [\n",
    "        Resnet_Q1(),\n",
    "        VGG_Q2(),\n",
    "        Inception_Q3(),\n",
    "        CustomNetwork_Q4()\n",
    "    ]\n",
    "\n",
    "\n",
    "    for network in Architectures:\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(\n",
    "            params=network.parameters(),\n",
    "            lr=LEARNING_RATE\n",
    "        )\n",
    "\n",
    "        for dataset in imageDataset:\n",
    "            if dataset.datasplit == \"train\":\n",
    "                print(\n",
    "                    \"Training {} Architecture on {} split of {}\".format(\n",
    "                        network.__class__.__name__,\n",
    "                        dataset.datasplit,\n",
    "                        dataset.__class__.__name__\n",
    "                    )\n",
    "                )\n",
    "                network.train()\n",
    "                train_dataloader = DataLoader(\n",
    "                    dataset=dataset,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    shuffle=True,\n",
    "                    num_workers=2,\n",
    "                    drop_last=True\n",
    "                )\n",
    "\n",
    "                trainer(\n",
    "                    gpu=GPU,\n",
    "                    dataloader=train_dataloader,\n",
    "                    network=network,\n",
    "                    criterion=criterion,\n",
    "                    optimizer=optimizer,\n",
    "                    epoch=EPOCH\n",
    "                )\n",
    "\n",
    "            elif dataset.datasplit == \"val\":\n",
    "                print(\n",
    "                    \"Validating {} Architecture on {} split of {}\".format(\n",
    "                        network.__class__.__name__,\n",
    "                        dataset.datasplit,\n",
    "                        dataset.__class__.__name__\n",
    "                    )\n",
    "                )\n",
    "                network.train()\n",
    "                val_dataloader = DataLoader(\n",
    "                    dataset=dataset,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    shuffle=True,\n",
    "                    num_workers=2,\n",
    "                    drop_last=True\n",
    "                )\n",
    "\n",
    "                validator(\n",
    "                    gpu=GPU,\n",
    "                    dataloader=val_dataloader,\n",
    "                    network=network,\n",
    "                    criterion=criterion,\n",
    "                    optimizer=optimizer\n",
    "                )\n",
    "\n",
    "            elif dataset.datasplit == \"test\":\n",
    "                print(\n",
    "                    \"Testing {} Architecture on {} split of {}\".format(\n",
    "                        network.__class__.__name__,\n",
    "                        dataset.datasplit,\n",
    "                        dataset.__class__.__name__\n",
    "                    )\n",
    "                )\n",
    "                network.eval()\n",
    "                test_dataloader = DataLoader(\n",
    "                    dataset=dataset,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    shuffle=True,\n",
    "                    num_workers=2,\n",
    "                    drop_last=True\n",
    "                )\n",
    "                test(\n",
    "                    gpu=GPU,\n",
    "                    dataloader=test_dataloader,\n",
    "                    network=network,\n",
    "                    criterion=None,\n",
    "                    optimizer=None)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20452.496988,
   "end_time": "2024-08-28T11:22:23.609674",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-28T05:41:31.112686",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
